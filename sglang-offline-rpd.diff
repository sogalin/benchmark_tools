diff --git a/python/sglang/bench_one_batch.py b/python/sglang/bench_one_batch.py
index de846066..ca021280 100644
--- a/python/sglang/bench_one_batch.py
+++ b/python/sglang/bench_one_batch.py
@@ -73,6 +73,7 @@ from sglang.srt.utils import (
     suppress_other_loggers,
 )
 
+from rpdTracerControl import rpdTracerControl
 
 @dataclasses.dataclass
 class BenchArgs:
@@ -84,6 +85,9 @@ class BenchArgs:
     correctness_test: bool = False
     # This is only used for correctness test
     cut_len: int = 4
+    enable_prefill_prof: bool = False
+    enable_decode_prof: bool = False
+
     profile: bool = False
     profile_filename_prefix: str = "profile"
 
@@ -104,6 +108,15 @@ class BenchArgs:
         )
         parser.add_argument("--correctness-test", action="store_true")
         parser.add_argument("--cut-len", type=int, default=BenchArgs.cut_len)
+        parser.add_argument(
+            "--enable-decode-prof",
+            action='store_true',
+            help="enable decode profiler.")
+        parser.add_argument(
+            "--enable-prefill-prof",
+            action='store_true',
+            help="enable prefill profiler.")
+
         parser.add_argument(
             "--profile", action="store_true", help="Use Torch Profiler."
         )
@@ -306,16 +319,7 @@ def synchronize(device):
 
 
 def latency_test_run_once(
-    run_name,
-    model_runner,
-    rank_print,
-    reqs,
-    batch_size,
-    input_len,
-    output_len,
-    device,
-    profile,
-    profile_filename_prefix,
+    is_warm_up, enable_prefill_prof, enable_decode_prof, tp_rank, run_name, model_runner, rank_print, reqs, batch_size, input_len, output_len, device, profile, profile_filename_prefix,
 ):
     max_batch_size = model_runner.max_total_num_tokens // (input_len + output_len)
     if batch_size > max_batch_size:
@@ -351,8 +355,14 @@ def latency_test_run_once(
     # Prefill
     synchronize(device)
     tic = time.time()
+    if enable_prefill_prof and not is_warm_up and tp_rank == 0:
+        print("Start profile Prefill")
+        prefill_profile = rpdTracerControl()
+        prefill_profile.start()
     next_token_ids, _, batch = extend(reqs, model_runner)
     synchronize(device)
+    if enable_prefill_prof and not is_warm_up and tp_rank == 0:
+        prefill_profile.stop()
     prefill_latency = time.time() - tic
     tot_latency += prefill_latency
     throughput = input_len * batch_size / prefill_latency
@@ -364,6 +374,11 @@ def latency_test_run_once(
 
     # Decode
     decode_latencies = []
+    if enable_decode_prof and not is_warm_up and tp_rank == 0:
+        print("Start profile Decode")
+        # Create first instance (this loads the profiler and creates the file)
+        decode_profile = rpdTracerControl()
+        decode_profile.start()
     for i in range(output_len - 1):
         synchronize(device)
         tic = time.time()
@@ -377,6 +392,8 @@ def latency_test_run_once(
             rank_print(
                 f"Decode.  latency: {latency:6.5f} s, throughput: {throughput:9.2f} token/s"
             )
+    if enable_decode_prof and not is_warm_up and tp_rank == 0:
+        decode_profile.stop()
 
     if profile:
         profiler.stop()
@@ -430,6 +447,10 @@ def latency_test(
     # Warm up
     rank_print("Warmup ...")
     latency_test_run_once(
+        True,
+        bench_args.enable_prefill_prof,
+        bench_args.enable_decode_prof,
+        tp_rank,
         bench_args.run_name,
         model_runner,
         rank_print,
@@ -451,6 +472,10 @@ def latency_test(
     ):
         reqs = prepare_synthetic_inputs_for_latency_test(bs, il)
         ret = latency_test_run_once(
+            False,
+            bench_args.enable_prefill_prof,
+            bench_args.enable_decode_prof,
+            tp_rank,
             bench_args.run_name,
             model_runner,
             rank_print,
@@ -459,7 +484,7 @@ def latency_test(
             il,
             ol,
             server_args.device,
-            bench_args.profile if tp_rank == 0 else None,
+            bench_args.profile if tp_rank == 0 else False,
             bench_args.profile_filename_prefix,
         )
         if ret is not None:
@@ -473,6 +498,12 @@ def latency_test(
 
 
 def main(server_args, bench_args):
+    if bench_args.enable_prefill_prof or bench_args.enable_decode_prof:
+        # Optionally call this class method before creating first instance
+        rpdTracerControl.setFilename(name = "trace.rpd", append=False)
+
+        # Create first instance (this loads the profiler and creates the file)
+        profile = rpdTracerControl()
     _set_envs_and_config(server_args)
 
     if server_args.model_path:
